# 题目二说明文档

关于题目二的四个目标，我认为我已经完成了3个。



## 实验报告

关于手写数字识别，我选择了使用CNN这一经典模型来进行训练和识别。

- 对于数据集，我选择了mnist和从kaggle上寻找的数据集（[Handwritten Digits 0 - 9](https://www.kaggle.com/datasets/olafkrastovski/handwritten-digits-0-9?select=6)）该数据集共包括21k张手写数字图片，为了均衡，我将其以训练集：测试集=9：1的比例进行了分割，并且每次训练随机选取19000张mnist中的图片和该数据集结合，使得总的训练集有约32k张图片。测试集约有10k张图片。

对于我自己寻找的训练集，样例如下：

![Three_full (869)](C:\Users\10065\Desktop\img\Three_full (869).jpg)

![Four_full (411)](C:\Users\10065\Desktop\img\Four_full (411).jpg)

![Six_full (346)](C:\Users\10065\Desktop\img\Six_full (346).jpg)

![Nine_full (421)](C:\Users\10065\Desktop\img\Nine_full (421).jpg)

- 关于网络结构，我一开始使用了最为简单的两层卷积层的网络来进行尝试，发现在仅仅使用mnist进行训练的时候，效果很好，但是对于我的自己添加的测试集和我自己手写的数字来说表现却很不好。

```python
class myModel(nn.Module):
    def __init__(self):
        super().__init__()
        
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)  #第一层卷积
        self.pool1 = nn.MaxPool2d(2)  #最大池化层
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)  # 第二层卷积3
        self.pool2 = nn.MaxPool2d(2) #最大池化层

        self.fc1 = nn.Linear(1600, 64)
        self.fc2 = nn.Linear(64, num_classes)

    # 前向传播
    def forward(self, x):
        x = self.pool1(F.relu(self.conv1(x))) #卷积后池化
        x = self.pool2(F.relu(self.conv2(x)))
        x = torch.flatten(x, start_dim=1)  #展平
        x = F.relu(self.fc1(x)) #relu激活函数
        x = self.fc2(x) #分类
        return x
```

​    于是我增大了模型的复杂程度，将其添加为4层卷积层，使用`relu`激活函数和最大池化的网络。同时在分类器中我还使用了dropout来防止过拟合, 以便增强泛化能力，识别我所写的数字，在训练过程中我还使用了adam优化器来进行优化。

```python
class improved_Model(nn.Module):
    def __init__(self): 
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        self.classifier = nn.Sequential(
            nn.Dropout(0.5),#dropout防止过拟合
            nn.Linear(64 * 7 * 7, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5), #dropout防止过拟合
            nn.Linear(512, num_classes)
        )

    # 前向传播
    def forward(self, x):
        x = self.features(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x
```

​    经过训练调整系数多次训练后，我的网络不仅在测试集和训练集上能够有很高的准确率，也能识别大部分我自己在电脑绘图软件和自己用纸笔所写的数字，效果良好。

![image-20240927094157876](img/image-20240927094157876.png)

  对于我使用电脑写的数字，例如

![2](C:\Users\10065\Desktop\img\2.png)

<center>
    2
</center>

![8](C:\Users\10065\Desktop\img\8.png)

<center>
    8
</center>
对于我使用笔纸所写的数字，如

![9](img/9.jpg)

![333](img/333.jpg)

![666](img/666.jpg)

  都能够识别正确。

- 此外，鉴于我前期阅读了d2l的`Modern Convolutional Neural Networks`章节，我对ResNet印象十分深刻，于是我也实现了使用ResNet的神经网络，使用了最经典的ResNet18网络来进行训练。经过训练，我发现ResNet在准确率上相比于我自己优化的网络略高，对于我自己手写的数字识别也更加准确。

  网络结构如下：

<img src="img/model1.onnx.png" alt="model1.onnx" style="zoom:50%;" />
